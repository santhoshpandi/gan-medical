from google.colab import drive
drive.mount("/content/drive/")

import tensorflow 
import keras  
import os
import glob 
from skimage import io 
import random 
import numpy as np
import matplotlib.pyplot as plt  
%matplotlib inline



dataset_path = '/content/drive/MyDrive/balz_crypto/Train'
class_names = ['Brain','Lungs','Brachial_Plexus']
 

brain_path = os.path.join(dataset_path, class_names[0], '*')
brain_path = glob.glob(brain_path)

lungs_path = os.path.join(dataset_path, class_names[1], '*')
lungs_path = glob.glob(lungs_path)

brach_path = os.path.join(dataset_path, class_names[2], '*')
brach_path = glob.glob(brach_path)


b_image = io.imread(brain_path[4])
l_image= io.imread(lungs_path[5])
bp_image = io.imread(brach_path[1])

i, (im1) = plt.subplots(1)
i.set_figwidth(15)
im1.imshow(b_image)


i, (im2) = plt.subplots(1)
i.set_figwidth(15)
im2.imshow(l_image)


i, (im3) = plt.subplots(1)
i.set_figwidth(15)
im3.imshow(bp_image)




i, (im11, im21, im31, im41) = plt.subplots(1, 4, sharey=True)
i.set_figwidth(20) 

im11.imshow(b_image)  
im21.imshow(b_image[:, : , 0])
im31.imshow(b_image[:, : , 1]) 
im41.imshow(b_image[:, : , 2]) 
i.suptitle('Original & RGB image channels')

from google.colab import drive
drive.mount('/content/drive')

norm_image = (bp_image - np.min(bp_image)) / (np.max(bp_image) - np.min(bp_image))
plt.imshow(norm_image)

import tensorflow as tf
split_dir = '/content/drive/MyDrive/balz_crypto'
train_dir = f'{split_dir}/Train/'
val_dir = f'{split_dir}/Test/'

# tf.data.Dataset object

train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir, 
                                                                    labels='inferred', 
                                                                    label_mode='categorical',
                                                                    batch_size=32,
                                                                    image_size=(32, 32))
val_dataset = tf.keras.preprocessing.image_dataset_from_directory(val_dir, 
                                                                  labels='inferred', 
                                                                  label_mode='categorical',
                                                                  batch_size=32,
                                                                  image_size=(32, 32))

#Lets do the Implementation of GAN

import tensorflow 
import keras  
import os
import glob 
from skimage import io 
from keras.preprocessing.image import ImageDataGenerator
import random 
import numpy as np
import matplotlib.pyplot as plt  
%matplotlib inline


import keras
from keras.layers import Dense, Conv2DTranspose, LeakyReLU, Reshape, BatchNormalization, Activation, Conv2D
from keras.models import Model, Sequential


def image_generator():

    generator = Sequential()

    generator.add(Dense(256*4*4, input_shape = (100,)))
    generator.add(LeakyReLU())
    generator.add(Reshape((4,4,256)))

    generator.add(Conv2DTranspose(128,kernel_size=3, strides=2, padding = "same"))
    generator.add(LeakyReLU(alpha=0.2))


    generator.add(Conv2DTranspose(128,kernel_size=3, strides=2, padding = "same"))
    generator.add(LeakyReLU(alpha=0.2))

    generator.add(Conv2DTranspose(128,kernel_size=3, strides=2, padding = "same"))
    generator.add(LeakyReLU(alpha=0.2))

    generator.add(Conv2D(3,kernel_size=3, padding = "same", activation='tanh'))

    return(generator)

model_generator = image_generator()

model_generator.summary()

import matplotlib.pyplot as plt
import numpy as np
 
def generate_data_entry(n_shows):
  X = np.random.randn(100 * n_shows)
  X = X.reshape(n_shows, 100)
  return X

def create_datas_fake(model_generator, n_shows):
  input = generate_data_entry(n_shows)
  X = model_generator.predict(input)
  y = np.zeros((n_shows, 1))
  return X,y

sample_number = 4
X,_ = create_datas_fake(model_generator, sample_number)

# Visualizing results
for i in range(sample_number):
    plt.subplot(2, 2, 1 + i)
    plt.axis('off')
    plt.imshow(X[i])

from keras.layers import Conv2D, Flatten, Dropout
from keras.optimizers import Adam

def image_discriminator():

    discriminator = Sequential()
    discriminator.add(Conv2D(64, kernel_size=3, padding = "same", input_shape = (32,32,3)))
    discriminator.add(LeakyReLU(alpha=0.2))

    discriminator.add(Conv2D(128, kernel_size=3,strides=(2,2), padding = "same"))
    discriminator.add(LeakyReLU(alpha=0.2))

    discriminator.add(Conv2D(128, kernel_size=3,strides=(2,2), padding = "same"))
    discriminator.add(LeakyReLU(alpha=0.2))

    discriminator.add(Conv2D(256, kernel_size=3, strides=(2,2), padding = "same"))
    discriminator.add(LeakyReLU(alpha=0.2))

    discriminator.add(Flatten())
    discriminator.add(Dropout(0.4))
    discriminator.add(Dense(1, activation='sigmoid'))

    opt = Adam(lr=0.0002 ,beta_1=0.5)
    discriminator.compile(loss='binary_crossentropy', optimizer= opt , metrics = ['accuracy'])

    return(discriminator)

model_discriminator = image_discriminator()
model_discriminator.summary()

import tensorflow as tf
split_dir = '/content/drive/MyDrive/balz_crypto'
train_dir = f'{split_dir}/Train/'
val_dir = f'{split_dir}/Test/'

# tf.data.Dataset object

train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir, 
                                                                    labels='inferred', 
                                                                    label_mode='categorical',
                                                                    batch_size=32,
                                                                    image_size=(32, 32))
val_dataset = tf.keras.preprocessing.image_dataset_from_directory(val_dir, 
                                                                  labels='inferred', 
                                                                  label_mode='categorical',
                                                                  batch_size=32,
                                                                  image_size=(32, 32))

%matplotlib inline
import matplotlib.pyplot as plt
import os
src_path = "/content/drive/MyDrive/balz_crypto/Test/"
sub_class = os.listdir(src_path)

fig = plt.figure(figsize=(10,5))


path = os.path.join(src_path,sub_class[1])


from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import numpy as np
import cv2
import os

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf

from keras.datasets import cifar10

def load_images():
    #(Xtrain, Ytrain), (_, _) = cifar10.load_data()
    import glob
    brain = glob.glob('/content/drive/MyDrive/balz_crypto/Train/Brain/*.*')
    lungs = glob.glob('/content/drive/MyDrive/balz_crypto/Train/Lungs/*.*')
    brach = glob.glob('/content/drive/MyDrive/balz_crypto/Train/Brachial_Plexus/*.*')


    data = []
    labels = []

    for i in brain:   
        image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',target_size= (32,32))
        image=np.array(image)
        data.append(image)
        labels.append(0)
    for i in lungs:   
        image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',target_size= (32,32))
        image=np.array(image)
        data.append(image)
        labels.append(1)
    for i in brach:   
        image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb',target_size= (32,32))
        image=np.array(image)
        data.append(image)
        labels.append(1)


    data = np.array(data)
    labels = np.array(labels)

    from sklearn.model_selection import train_test_split
    X_train, X_test, ytrain, ytest = train_test_split(data, labels, test_size=0.2,random_state=42)

    # Train the brain
    indice = np.where(ytrain == 0)
    indice = indice[0]
    X_train = X_train[indice, :,:,:]

    # Normalize to float
    X = X_train.astype('float32')
    X = (X - 127.5) / 127.5

    return X

print(load_images().shape)

import random

def load_real_data(dataset, n_shows):
  ix = np.random.randint(0, dataset.shape[0], n_shows)
  X = dataset[ix]
  y = np.ones((n_shows, 1))
  return X,y

def load_data_fake(n_shows):
  X = np.random.rand(32 * 32 * 3 * n_shows)
  X = -1 + X * 2
  X = X.reshape((n_shows, 32,32,3))
  y = np.zeros((n_shows, 1))
  return X,y

def train_discriminator(model, dataset, n_iterations=20, batch = 128):
  medio_batch = int(batch/2)

  for i in range(n_iterations):
    X_real, y_real = load_real_data(dataset, medio_batch)
    _, acc_real = model.train_on_batch(X_real, y_real)

    X_fake, y_fake = load_data_fake(medio_batch)
    _, acc_fake = model.train_on_batch(X_fake, y_fake)

    print(str(i+1) + ' Real:' + str(acc_real*100) + ', Fake:' + str(acc_fake*100))

import tensorflow as tf
tf.config.run_functions_eagerly(True)

dataset = load_images()
train_discriminator(model_discriminator, dataset)

def create_gan(discriminator, generator):
    discriminator.trainable=False
    gan = Sequential()
    gan.add(generator)
    gan.add(discriminator)

    opt = Adam(lr=0.0002,beta_1=0.5) 
    gan.compile(loss = "binary_crossentropy", optimizer = opt)

    return gan

gan = create_gan(model_discriminator,model_generator)
gan.summary()

import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from datetime import datetime

def show_generated_images(datos_fake, epoch):

  now = datetime.now()
  now = now.strftime("%Y%m%d_%H%M%S")

  # We make the data go from 0 to 1
  datos_fake = (datos_fake + 1) / 2.0

  for i in range(10):
    plt.imshow(datos_fake[i])
    plt.axis('off')
    name = str(epoch) + '_imagen_generated_' + str(i) + '.png'
    plt.savefig(name, bbox_inches='tight')
    plt.close()

acc_real_history = []
acc_fake_history = []
loss_real_history = []
loss_fake_history = []
def evaluate_y_save(model_generator, epoch, medio_dataset):
  
  # We save the model
  now = datetime.now()
  now = now.strftime("%Y%m%d_%H%M%S")
  name = str(epoch) + '_' + str(now)+"_model_generator_" + '.h5'
  model_generator.save(name)

  # We generate new data
  X_real,Y_real = load_real_data(dataset, medio_dataset)
  X_fake, Y_fake =  create_datas_fake(model_generator,medio_dataset)

  # We evaluate the model
  loss_real, acc_real = model_discriminator.evaluate(X_real, Y_real)
  loss_fake, acc_fake = model_discriminator.evaluate(X_fake, Y_fake)
  acc_real_history.append(acc_real)
  acc_fake_history.append(acc_fake)
  loss_real_history.append(loss_real)
  loss_fake_history.append(loss_fake)
  print('Accuracy Real:' + str(acc_real*100) + '% Accuracy Fake:' + str(acc_fake*100)+'%')

def training(datos, model_generator, model_discriminator, epochs, n_batch, start = 0):
  dimension_batch = int(datos.shape[0]/n_batch)
  medio_dataset = int(n_batch/2)


  for epoch in range(start, start + epochs):
    
    for batch in range(n_batch):

      
      X_real,Y_real = load_real_data(dataset, medio_dataset)


      
      coste_discriminator_real, _ = model_discriminator.train_on_batch(X_real, Y_real)
      X_fake, Y_fake =  create_datas_fake(model_generator,medio_dataset)

      coste_discriminator_fake, _ = model_discriminator.train_on_batch(X_fake, Y_fake)

      
      X_gan = generate_data_entry(medio_dataset)
      Y_gan = np.ones((medio_dataset, 1))

      
      coste_gan = gan.train_on_batch(X_gan, Y_gan)

    
    if (epoch+1) % 2 == 0:
      evaluate_y_save(model_generator,epoch = epoch, medio_dataset= medio_dataset)
      show_generated_images(X_real, epoch = epoch)

training(dataset, model_generator, model_discriminator, epochs = 4, n_batch=32, start = 0)

plt.plot(acc_real_history,color='blue')
plt.xlabel("Number of Epochs")
plt.ylabel("Accuracy of Real Images")
plt.title("Performance of Real Images")

plt.plot(loss_real_history,color='red')
plt.xlabel("Number of Epochs")
plt.ylabel("Loss of Real Images")
plt.title("Performance of Real Images")

plt.plot(acc_fake_history,color='green')
plt.xlabel("Number of Epochs")
plt.ylabel("Accuracy of Fake Images")
plt.title("Performance of Fake Images")

plt.plot(loss_fake_history,color='red')
plt.xlabel("Number of Epochs")
plt.ylabel("Loss of Fake Images")
plt.title("Performance of Fake Images")

X_fake, _ = create_datas_fake(n_shows=49, model_generator=model_generator)
X_fake = (X_fake+1)/2

for i in range(49):
    fig=plt.imshow(X_fake[i])
    fig.set_cmap('hot')
    fig.axes.get_xaxis().set_visible(False)
    fig.axes.get_yaxis().set_visible(False)
    plt.savefig('/content/drive/MyDrive/balz_crypto_private_key_by_GAN/private_key.png', bbox_inches='tight')

from PIL import Image

# Load the image
img = Image.open("/content/drive/MyDrive/balz_crypto_private_key_by_GAN/private_key.png")
resized_img = img.resize((256, 256))
resized_img.save("/content/drive/MyDrive/balz_crypto_private_key_by_GAN/private_key.png")

# Get the size of the image
width, height = img.size
width1,height1=resized_img.size




#Implementing XOR Algorithm

#Initial Image
from matplotlib import pyplot as plt
from matplotlib import image as mpimg


image = mpimg.imread("/content/drive/MyDrive/balz_crypto/Test/Brain/11 no.jpg")
plt.imshow(image)
plt.show()
import math
from PIL import Image

# Load the image
img = Image.open("/content/drive/MyDrive/balz_crypto/Test/Brain/11 no.jpg")

# Convert the image to grayscale
img = img.convert('L')

# Calculate the histogram of pixel values
histogram = img.histogram()

# Normalize the histogram
num_pixels = img.size[0] * img.size[1]
normalized_histogram = [float(x) / num_pixels for x in histogram]

# Calculate the entropy of the image
entropy = -sum([p * math.log2(p + 1e-10) for p in normalized_histogram])

# Print the entropy value
print(f"The entropy of the private key image is {entropy:.2f}")



#Encryption

from PIL import Image
import numpy as np

def encrypt_image(image_path, private_key_path):
    img = Image.open(image_path).convert('RGB')
    private_key = Image.open(private_key_path).convert('RGB')
    private_key = private_key.resize(img.size)
    img_array = np.array(img)
    private_key_array = np.array(private_key)
    encrypted_array = np.bitwise_xor(img_array, private_key_array)
    encrypted_img = Image.fromarray(encrypted_array)
    encrypted_img.save('encrypted.png')
    image = mpimg.imread("encrypted.png")
    plt.imshow(image)
    plt.show()
    
    # Load the image
    img = Image.open("encrypted.png")

    # Convert the image to grayscale
    img = img.convert('L')

    # Calculate the histogram of pixel values
    histogram = img.histogram()

    # Normalize the histogram
    num_pixels = img.size[0] * img.size[1]
    normalized_histogram = [float(x) / num_pixels for x in histogram]

    # Calculate the entropy of the image
    entropy = -sum([p * math.log2(p + 1e-10) for p in normalized_histogram])

    # Print the entropy value
    print(f"The entropy of the private key image is {entropy:.2f}")

    


encrypt_image('/content/drive/MyDrive/balz_crypto/Test/Brain/11 no.jpg', '/content/drive/MyDrive/balz_crypto_private_key_by_GAN/private_key.png')


from PIL import Image

def known_plaintext_attack(plaintext_path, encrypted_path):
    # Load the known plaintext and encrypted images
    plaintext = Image.open(plaintext_path)
    encrypted = Image.open(encrypted_path)

    # Ensure that the images have the same size
    if plaintext.size != encrypted.size:
        raise ValueError("Images must have the same size")

    # Extract the pixel data from the images
    plaintext_pixels = plaintext.load()
    encrypted_pixels = encrypted.load()

    # Iterate over the pixels and compute the differences
    key = []
    for i in range(plaintext.size[0]):
        for j in range(plaintext.size[1]):
            r_p, g_p, b_p = plaintext_pixels[i, j]
            r_e, g_e, b_e = encrypted_pixels[i, j]
            key.append((r_p ^ r_e, g_p ^ g_e, b_p ^ b_e))

    # Convert the list of tuples to a one-dimensional list of integers
    flat_key = [val for tpl in key for val in tpl]

    # Convert the list to a bytes object
    data = bytes(flat_key)

    # Create a new image from the bytes object
    recovered_img = Image.frombytes(encrypted.mode, encrypted.size, data)

    # Save the recovered image
    recovered_img.save("recovered.png")
    image1 = mpimg.imread("/content/recovered.png")
    plt.imshow(image1)
    plt.show()


known_plaintext_attack('/content/drive/MyDrive/balz_crypto/Test/Brain/11 no.jpg','/content/encrypted.png')

#Decryption

from PIL import Image
import numpy as np

def decrypt_image(image_path, private_key_path):
    encrypted_img = Image.open(image_path).convert('RGB')
    private_key = Image.open(private_key_path).convert('RGB')
    private_key = private_key.resize(encrypted_img.size)
    encrypted_array = np.array(encrypted_img)
    private_key_array = np.array(private_key)
    decrypted_array = np.bitwise_xor(encrypted_array, private_key_array)
    decrypted_img = Image.fromarray(decrypted_array)
    decrypted_img.save('decrypted.png')
    image1 = mpimg.imread("/content/decrypted.png")
    plt.imshow(image1)
    plt.show()



decrypt_image('/content/encrypted.png', '/content/drive/MyDrive/balz_crypto_private_key_by_GAN/private_key.png')








# Known plaintext Attack

#Original Image
image = mpimg.imread("/content/drive/MyDrive/balz_crypto/Test/Brain/11 no.jpg")
plt.imshow(image)
plt.show()

from PIL import Image

def encrypt_image(image_path, key_path):
    img = Image.open(image_path)
    key = Image.open(key_path).convert("L")  # convert to grayscale
    pixels = img.load()
    key_pixels = key.load()
    for i in range(img.size[0]):
        for j in range(img.size[1]):
            r, g, b = pixels[i, j]
            k = key_pixels[i, j]
            pixels[i, j] = (r ^ k, g ^ k, b ^ k)
    img.save("encrypted_image.png")
    image1 = mpimg.imread("/content/encrypted_image.png")
    plt.imshow(image1)
    plt.show()


encrypt_image('/content/drive/MyDrive/balz_crypto/Test/Brain/11 no.jpg','/content/drive/MyDrive/balz_crypto_private_key_by_GAN/private_key.png')



from PIL import Image

def known_plaintext_attack(plaintext_path, encrypted_path):
    # Load the known plaintext and encrypted images
    plaintext = Image.open(plaintext_path)
    encrypted = Image.open(encrypted_path)

    # Ensure that the images have the same size
    if plaintext.size != encrypted.size:
        raise ValueError("Images must have the same size")

    # Extract the pixel data from the images
    plaintext_pixels = plaintext.load()
    encrypted_pixels = encrypted.load()

    # Iterate over the pixels and compute the differences
    key = []
    for i in range(plaintext.size[0]):
        for j in range(plaintext.size[1]):
            r_p, g_p, b_p = plaintext_pixels[i, j]
            r_e, g_e, b_e = encrypted_pixels[i, j]
            key.append((r_p ^ r_e, g_p ^ g_e, b_p ^ b_e))

    # Convert the list of tuples to a one-dimensional list of integers
    flat_key = [val for tpl in key for val in tpl]

    # Convert the list to a bytes object
    data = bytes(flat_key)

    # Create a new image from the bytes object
    recovered_img = Image.frombytes(encrypted.mode, encrypted.size, data)

    # Save the recovered image
    recovered_img.save("recovered_image.png")
    image1 = mpimg.imread("/content/recovered_image.png")
    plt.imshow(image1)
    plt.show()


known_plaintext_attack('/content/drive/MyDrive/balz_crypto/Test/Brain/11 no.jpg','/content/encrypted.png')

from PIL import Image

def decrypt_image(image_path, key_path):
    img = Image.open(image_path)
    key = Image.open(key_path).convert("L")  # convert to grayscale
    pixels = img.load()
    key_pixels = key.load()
    for i in range(img.size[0]):
        for j in range(img.size[1]):
            r, g, b = pixels[i, j]
            k = key_pixels[i, j]
            pixels[i, j] = (r ^ k, g ^ k, b ^ k)
    img.save("decrypted_image.png")
    image1 = mpimg.imread("/content/decrypted_image.png")
    plt.imshow(image1)
    plt.show()


decrypt_image('/content/encrypted_image.png','/content/drive/MyDrive/balz_crypto_private_key_by_GAN/private_key.png')





#frequency analysis attack

from PIL import Image
import numpy as np

# Load the encrypted image
encrypted_image = Image.open("encrypted_image.png")
encrypted_pixels = np.array(encrypted_image)

# Compute the frequency of each color in the encrypted image
color_counts = {}
for i in range(encrypted_pixels.shape[0]):
    for j in range(encrypted_pixels.shape[1]):
        color = tuple(encrypted_pixels[i,j,:])
        if color in color_counts:
            color_counts[color] += 1
        else:
            color_counts[color] = 1

# Sort the colors by frequency
sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)

# Print the most common colors
print("Most common colors:")
for i in range(10):
    print(sorted_colors[i])

# Replace the most common color with white
most_common_color = sorted_colors[0][0]
for i in range(encrypted_pixels.shape[0]):
    for j in range(encrypted_pixels.shape[1]):
        color = tuple(encrypted_pixels[i,j,:])
        if color == most_common_color:
            encrypted_pixels[i,j,:] = [255, 255, 255]

# Save the decrypted image
decrypted_image = Image.fromarray(encrypted_pixels)
decrypted_image.save("freq_decrypted_image.png")

image1 = mpimg.imread("/content/freq_decrypted_image.png")
plt.imshow(image1)
plt.show()

image1 = mpimg.imread("/content/decrypted_image.png")
plt.imshow(image1)
plt.show()




#Differential Attack

# define the differential attack
def differential_attack(encrypted_image_path, diff_image_path):
    img = Image.open(encrypted_image_path)
    pixels = img.load()

    # create the difference image
    diff_img = Image.new(img.mode, img.size)
    diff_pixels = diff_img.load()

    # compute the difference of each pixel with its right neighbor and store it in the diff image
    for i in range(img.size[0]-1):
        for j in range(img.size[1]):
            r1, g1, b1 = pixels[i, j]
            r2, g2, b2 = pixels[i+1, j]
            diff_pixels[i, j] = (r1 ^ r2, g1 ^ g2, b1 ^ b2)

    diff_img.save(diff_image_path)
    image1 = mpimg.imread("/content/diff_image.png")
    plt.imshow(image1)
    plt.show()

differential_attack("/content/encrypted_image.png", "diff_image.png")

